{"cells":[{"cell_type":"markdown","id":"80517dbc","metadata":{"id":"80517dbc"},"source":["# Teach an LLM to do additions"]},{"cell_type":"code","execution_count":1,"id":"ae993bb9","metadata":{"executionInfo":{"elapsed":4408,"status":"ok","timestamp":1738666476585,"user":{"displayName":"Nathanaël Fijalkow","userId":"05325553244112431603"},"user_tz":-60},"id":"ae993bb9"},"outputs":[],"source":["import torch\n","from torch import nn\n","from torch.nn import functional as F\n","\n","import random\n","import math\n","import re\n","import time"]},{"cell_type":"code","execution_count":2,"id":"OzGh9ahKF17h","metadata":{"executionInfo":{"elapsed":1908,"status":"ok","timestamp":1738666479467,"user":{"displayName":"Nathanaël Fijalkow","userId":"05325553244112431603"},"user_tz":-60},"id":"OzGh9ahKF17h"},"outputs":[],"source":["number_bits = 3\n","\n","dataset_size = 64_000\n","train_proportion = 0.9\n","\n","log_interval = 200\n","batch_size = 64\n","epochs = 4\n","learning_rate = 1e-4"]},{"cell_type":"markdown","id":"6c054bed","metadata":{"id":"6c054bed"},"source":["## Step 1: Construct a tokenizer"]},{"cell_type":"code","execution_count":3,"id":"t6aC9uNeIR6C","metadata":{"executionInfo":{"elapsed":48,"status":"ok","timestamp":1738666479467,"user":{"displayName":"Nathanaël Fijalkow","userId":"05325553244112431603"},"user_tz":-60},"id":"t6aC9uNeIR6C"},"outputs":[],"source":["pad_token=\"[PAD]\"\n","eos_token=\"[EOS]\""]},{"cell_type":"markdown","id":"BMvT0B-MGBnY","metadata":{"id":"BMvT0B-MGBnY"},"source":["### Option 1: character-level"]},{"cell_type":"code","execution_count":4,"id":"g2QiF-otFur3","metadata":{"executionInfo":{"elapsed":47,"status":"ok","timestamp":1738666479468,"user":{"displayName":"Nathanaël Fijalkow","userId":"05325553244112431603"},"user_tz":-60},"id":"g2QiF-otFur3"},"outputs":[],"source":["class character_level_tokenizer:\n","    \"\"\"\n","    character-level\n","    \"\"\"\n","    def __init__(self):\n","        self.vocab = [str(x) for x in range(10)] + [\"+\", \"=\"] + [pad_token, eos_token]\n","        self.token_to_id = {v : k for k, v in enumerate(self.vocab)}\n","        self.id_to_token = {k : v for k, v in enumerate(self.vocab)}\n","        self.ntokens = len(self.vocab)\n","        self.pattern = f\"[^{re.escape(''.join(self.vocab))}]\"\n","\n","    def clean(self, text):\n","        \"\"\"\n","        removes all characters not in the vocabulary\n","        \"\"\"\n","        out = re.sub(self.pattern, \"\", text)\n","        return out\n","\n","    def pre_tokenization(self, text):\n","        \"\"\"\n","        character-level\n","        \"\"\"\n","        return [c for c in text]\n","\n","    def encode(self, text):\n","        text_list = self.pre_tokenization(self.clean(text))\n","        return [self.token_to_id[c] for c in text_list]\n","\n","    def decode(self, token_list):\n","        return \"\".join([self.id_to_token[x] for x in token_list])"]},{"cell_type":"code","execution_count":5,"id":"QuCc6jF5F8hK","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":46,"status":"ok","timestamp":1738666479468,"user":{"displayName":"Nathanaël Fijalkow","userId":"05325553244112431603"},"user_tz":-60},"id":"QuCc6jF5F8hK","outputId":"1e850852-eb3c-48ca-cb33-6dbc185dcc8e"},"outputs":[{"data":{"text/plain":["14"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer = character_level_tokenizer()\n","ntokens = tokenizer.ntokens\n","ntokens"]},{"cell_type":"code","execution_count":6,"id":"8FXW2K-1Jd-P","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":37,"status":"ok","timestamp":1738666479468,"user":{"displayName":"Nathanaël Fijalkow","userId":"05325553244112431603"},"user_tz":-60},"id":"8FXW2K-1Jd-P","outputId":"621d6368-626f-46a5-b0d3-3d931502376b"},"outputs":[{"data":{"text/plain":["([1, 2, 10, 4, 2, 11], '12+42=')"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["prompt = \"12 + 42 =\"\n","inputs = tokenizer.encode(prompt)\n","inputs, tokenizer.decode(inputs)"]},{"cell_type":"markdown","id":"j3gckvebGGYt","metadata":{"id":"j3gckvebGGYt"},"source":["### Option 2: reversed character-level"]},{"cell_type":"code","execution_count":7,"id":"tQI-LUi0LOCm","metadata":{"executionInfo":{"elapsed":28,"status":"ok","timestamp":1738666479468,"user":{"displayName":"Nathanaël Fijalkow","userId":"05325553244112431603"},"user_tz":-60},"id":"tQI-LUi0LOCm"},"outputs":[],"source":["class reversed_character_level_tokenizer:\n","    \"\"\"\n","    reversed character-level\n","    \"\"\"\n","    def __init__(self):\n","        self.vocab = [str(x) for x in range(10)] + [\"+\", \"=\"] + [pad_token, eos_token]\n","        self.token_to_id = {v : k for k, v in enumerate(self.vocab)}\n","        self.id_to_token = {k : v for k, v in enumerate(self.vocab)}\n","        self.ntokens = len(self.vocab)\n","        self.pattern = f\"[^{re.escape(''.join(self.vocab))}]\"\n","\n","    def clean(self, text):\n","        \"\"\"\n","        removes all characters not in the vocabulary\n","        \"\"\"\n","        out = re.sub(self.pattern, \"\", text)\n","        return out\n","\n","    def pre_tokenization(self, text):\n","        output = []\n","        curr = \"\"\n","        i = 0\n","        while(i \u003c len(text)):\n","            if text[i].isdigit():\n","                curr += text[i]\n","            else:\n","                if curr != \"\":\n","                    output.append(curr)\n","                curr = \"\"\n","                output.append(text[i])\n","            i += 1\n","        if curr != \"\":\n","            output.append(curr)\n","        return output\n","\n","    def encode(self, text):\n","        text_list = self.pre_tokenization(self.clean(text))\n","        output = []\n","        for x in text_list:\n","            output += [self.token_to_id[c] for c in reversed(x)]\n","        return output\n","\n","    def decode(self, token_list):\n","        output = \"\"\n","        i = 0\n","        while(i \u003c len(token_list)):\n","            if token_list[i] \u003e= 10:\n","                output += self.id_to_token[token_list[i]]\n","                i += 1\n","            else:\n","                number = []\n","                while(i \u003c len(token_list) and token_list[i] \u003c 10):\n","                    number.append(self.id_to_token[token_list[i]])\n","                    i += 1\n","                output += \"\".join(reversed(number))\n","        return output"]},{"cell_type":"code","execution_count":8,"id":"cMdwG630Lf-z","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27,"status":"ok","timestamp":1738666479468,"user":{"displayName":"Nathanaël Fijalkow","userId":"05325553244112431603"},"user_tz":-60},"id":"cMdwG630Lf-z","outputId":"4ea8e58c-abe4-4308-de54-5f02a42b1ff8"},"outputs":[{"data":{"text/plain":["14"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer = reversed_character_level_tokenizer()\n","ntokens = tokenizer.ntokens\n","ntokens"]},{"cell_type":"code","execution_count":9,"id":"erw9xvSBLmWy","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1738666479468,"user":{"displayName":"Nathanaël Fijalkow","userId":"05325553244112431603"},"user_tz":-60},"id":"erw9xvSBLmWy","outputId":"83777d34-2dc8-4661-98bb-720650794375"},"outputs":[{"data":{"text/plain":["([2, 1, 10, 2, 4, 11], '12+42=')"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["prompt = \"12 + 42 = \"\n","inputs = tokenizer.encode(prompt)\n","inputs, tokenizer.decode(inputs)"]},{"cell_type":"code","execution_count":10,"id":"17365bbf","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20,"status":"ok","timestamp":1738666479468,"user":{"displayName":"Nathanaël Fijalkow","userId":"05325553244112431603"},"user_tz":-60},"id":"17365bbf","outputId":"8b0ca985-a862-4d80-f570-05e43f084546"},"outputs":[{"data":{"text/plain":["([2, 1, 10, 2, 4, 11, 4, 5], '12+42=54')"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["prompt_answer = \"12 + 42 = 54\"\n","inputs = tokenizer.encode(prompt_answer)\n","inputs, tokenizer.decode(inputs)"]},{"cell_type":"markdown","id":"FaUU862z_jre","metadata":{"id":"FaUU862z_jre"},"source":["### Option 3: aligning numbers"]},{"cell_type":"code","execution_count":11,"id":"Lw3p1jpM-Pkc","metadata":{"executionInfo":{"elapsed":19,"status":"ok","timestamp":1738666479469,"user":{"displayName":"Nathanaël Fijalkow","userId":"05325553244112431603"},"user_tz":-60},"id":"Lw3p1jpM-Pkc"},"outputs":[],"source":["class aligned_tokenizer:\n","    \"\"\"\n","    aligns the numbers, from right to left\n","    \"\"\"\n","    def __init__(self):\n","        self.vocab = [str(x) for x in range(10)] + [\"+\", \"=\"] + [\"F\", \"S\"] + [pad_token, eos_token]\n","        self.token_to_id = {v : k for k, v in enumerate(self.vocab)}\n","        self.id_to_token = {k : v for k, v in enumerate(self.vocab)}\n","        self.ntokens = len(self.vocab)\n","        self.pattern = f\"[^{re.escape(''.join(self.vocab))}]\"\n","\n","    def clean(self, text):\n","        \"\"\"\n","        removes all characters not in the vocabulary\n","        \"\"\"\n","        out = re.sub(self.pattern, \"\", text)\n","        return out\n","\n","    def encode_prompt(self, num1, num2):\n","        max_length = max([len(num1), len(num2)])\n","        if len(num1) \u003c max_length:\n","            num1 = num1 + \"0\" * (max_length - len(num1))\n","        if len(num2) \u003c max_length:\n","            num2 = num2 + \"0\" * (max_length - len(num2))\n","        out = []\n","        for (x,y) in zip(num1, num2):\n","            out += [self.token_to_id[\"F\"], self.token_to_id[x], self.token_to_id[\"S\"], self.token_to_id[y]]\n","        return out\n","\n","    def encode(self, text):\n","        text = self.clean(text)\n","        splits = re.split(\"[=+]\", text)\n","        splits = [split for split in splits if len(split) \u003e 0]\n","        if len(splits) == 1:\n","            # encoding an answer\n","            return [self.token_to_id[c] for c in text]\n","        if len(splits) == 2:\n","            # encoding a prompt\n","            return self.encode_prompt(splits[0][::-1], splits[1][::-1]) + [self.token_to_id[\"=\"]]\n","        if len(splits) == 3:\n","            # encoding a prompt + answer\n","            encoded_prompt = self.encode_prompt(splits[0][::-1], splits[1][::-1]) + [self.token_to_id[\"=\"]]\n","            encoded_answer = [self.token_to_id[c] for c in splits[2]] + [self.token_to_id[eos_token]]\n","            return encoded_prompt + encoded_answer\n","\n","    def decode_prompt(self, token_list):\n","        i = 0\n","        num1 = \"\"\n","        num2 = \"\"\n","        while(i \u003c len(token_list) and token_list[i] != self.token_to_id[\"=\"]):\n","            if token_list[i] == self.token_to_id[pad_token]:\n","                i += 1\n","                continue\n","            assert(self.id_to_token[token_list[i]] == \"F\")\n","            x = self.id_to_token[token_list[i+1]]\n","            assert(self.id_to_token[token_list[i+2]] == \"S\")\n","            y = self.id_to_token[token_list[i+3]]\n","            num1 += x\n","            num2 += y\n","            i += 4\n","        return (num1[::-1] + \" + \" + num2[::-1] + \" = \", i + 1)\n","\n","    def decode(self, token_list):\n","        if self.token_to_id[\"=\"] in token_list:\n","            output, i = self.decode_prompt(token_list)\n","        else:\n","            output, i = \"\", 0\n","        number = []\n","        while(i \u003c len(token_list) and token_list[i] \u003c 10):\n","            number.append(self.id_to_token[token_list[i]])\n","            i += 1\n","        output += \"\".join(number)\n","        return output"]},{"cell_type":"code","execution_count":12,"id":"dDMRMDt-BiUp","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1738666479470,"user":{"displayName":"Nathanaël Fijalkow","userId":"05325553244112431603"},"user_tz":-60},"id":"dDMRMDt-BiUp","outputId":"cb90c342-f5ea-4874-f65b-ff18d7f7d857"},"outputs":[{"data":{"text/plain":["16"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer = aligned_tokenizer()\n","ntokens = tokenizer.ntokens\n","ntokens"]},{"cell_type":"code","execution_count":13,"id":"ro8k6CHUBiUq","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1738666479470,"user":{"displayName":"Nathanaël Fijalkow","userId":"05325553244112431603"},"user_tz":-60},"id":"ro8k6CHUBiUq","outputId":"991f051a-7731-4f44-8160-0ecece11ced6"},"outputs":[{"data":{"text/plain":["([12, 2, 13, 2, 12, 1, 13, 4, 11], '12 + 42 = ')"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["prompt = \"12 + 42 = \"\n","inputs = tokenizer.encode(prompt)\n","inputs, tokenizer.decode(inputs)"]},{"cell_type":"code","execution_count":14,"id":"4d85ef68","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1738666479470,"user":{"displayName":"Nathanaël Fijalkow","userId":"05325553244112431603"},"user_tz":-60},"id":"4d85ef68","outputId":"df60dc73-a6b0-4ffa-9228-7473b6b80d4f"},"outputs":[{"data":{"text/plain":["([12, 2, 13, 2, 12, 1, 13, 4, 11, 5, 4, 15], '12 + 42 = 54')"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["prompt_answer = \"12 + 42 = 54\"\n","inputs = tokenizer.encode(prompt_answer)\n","inputs, tokenizer.decode(inputs)"]},{"cell_type":"markdown","id":"_hkXzD1VXUG4","metadata":{"id":"_hkXzD1VXUG4"},"source":["We choose the tokenizer to be used here:"]},{"cell_type":"code","execution_count":15,"id":"do9Akgz_XO-J","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1738666479470,"user":{"displayName":"Nathanaël Fijalkow","userId":"05325553244112431603"},"user_tz":-60},"id":"do9Akgz_XO-J","outputId":"53f9b5ac-f8d0-4195-9e64-ce6fa809399c"},"outputs":[{"data":{"text/plain":["16"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["# tokenizer = character_level_tokenizer()\n","# tokenizer = reversed_character_level_tokenizer()\n","tokenizer = aligned_tokenizer()\n","\n","ntokens = tokenizer.ntokens\n","ntokens"]},{"cell_type":"markdown","id":"491af297","metadata":{"id":"491af297"},"source":["## Step 2: Create a dataset for arithmetic operations"]},{"cell_type":"code","execution_count":16,"id":"daa90f31","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1738666479470,"user":{"displayName":"Nathanaël Fijalkow","userId":"05325553244112431603"},"user_tz":-60},"id":"daa90f31","outputId":"dec76c82-950f-4311-bc4d-a4e00a228aaa"},"outputs":[{"data":{"text/plain":["('712+51=', '763')"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["def sample_datapoint(number_bits = 3):\n","    \"\"\"\n","    returns a string containing two random numbers on `number_bits` many bits and their sum.\n","    \"\"\"\n","    a_list = [random.randint(0, 9) for _ in range(number_bits)]\n","    b_list = [random.randint(0, 9) for _ in range(number_bits)]\n","    a_int = int(\"\".join([str(x) for x in a_list]))\n","    b_int = int(\"\".join([str(x) for x in b_list]))\n","    sum_int = a_int + b_int\n","    return (str(a_int) + \"+\" + str(b_int) + \"=\", str(sum_int))\n","\n","sample_datapoint(3)"]},{"cell_type":"code","execution_count":17,"id":"b6e861d2","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1738666479470,"user":{"displayName":"Nathanaël Fijalkow","userId":"05325553244112431603"},"user_tz":-60},"id":"b6e861d2","outputId":"1377b17b-9de1-42a6-d69c-487e723f44be"},"outputs":[{"data":{"text/plain":["[('5+32=', '37'),\n"," ('373+675=', '1048'),\n"," ('590+611=', '1201'),\n"," ('396+312=', '708')]"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["data = []\n","for _ in range(dataset_size):\n","    data.append(sample_datapoint(number_bits))\n","data[:4]"]},{"cell_type":"code","execution_count":18,"id":"fee85050","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1738666479470,"user":{"displayName":"Nathanaël Fijalkow","userId":"05325553244112431603"},"user_tz":-60},"id":"fee85050","outputId":"2c5dff77-b753-43ca-d34f-2e5ca924cbcf"},"outputs":[{"data":{"text/plain":["(57600, 6400)"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["data_train = data[: int(train_proportion * dataset_size)]\n","data_test = data[int(train_proportion * dataset_size):]\n","\n","len(data_train),len(data_test)"]},{"cell_type":"markdown","id":"37200598","metadata":{"id":"37200598"},"source":["## Step 3: Construct a model"]},{"cell_type":"code","execution_count":19,"id":"91674239","metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1738666479470,"user":{"displayName":"Nathanaël Fijalkow","userId":"05325553244112431603"},"user_tz":-60},"id":"91674239"},"outputs":[],"source":["class PositionalEncoding(nn.Module):\n","    r\"\"\"Inject some information about the relative or absolute position of the tokens in the sequence.\n","        The positional encodings have the same dimension as the embeddings, so that the two can be summed.\n","        Here, we use sine and cosine functions of different frequencies.\n","    .. math:\n","        \\text{PosEncoder}(pos, 2i) = sin(pos/10000^(2i/d_model))\n","        \\text{PosEncoder}(pos, 2i+1) = cos(pos/10000^(2i/d_model))\n","        \\text{where pos is the word position and i is the embed idx)\n","    Args:\n","        d_model: the embed dim (required).\n","        dropout: the dropout value (default=0.1).\n","        max_len: the max. length of the incoming sequence (default=5000).\n","    \"\"\"\n","\n","    def __init__(self, d_model, dropout=0.1, max_len=5000):\n","        super(PositionalEncoding, self).__init__()\n","        self.dropout = nn.Dropout(p=dropout)\n","\n","        pe = torch.zeros(max_len, d_model)\n","        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n","        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n","        pe[:, 0::2] = torch.sin(position * div_term)\n","        pe[:, 1::2] = torch.cos(position * div_term)\n","        pe = pe.unsqueeze(0).transpose(0, 1)\n","        self.register_buffer('pe', pe)\n","\n","    def forward(self, x):\n","        r\"\"\"Inputs of forward function\n","        Args:\n","            x: the sequence fed to the positional encoder model (required).\n","        Shape:\n","            x: [sequence length, batch size, embed dim]\n","            output: [sequence length, batch size, embed dim]\n","        \"\"\"\n","\n","        x = x + self.pe[:x.size(0), :]\n","        return self.dropout(x)"]},{"cell_type":"code","execution_count":20,"id":"4eb278ab","metadata":{"executionInfo":{"elapsed":1805,"status":"ok","timestamp":1738666481268,"user":{"displayName":"Nathanaël Fijalkow","userId":"05325553244112431603"},"user_tz":-60},"id":"4eb278ab"},"outputs":[],"source":["class TransformerModel(nn.Transformer):\n","    def __init__(self, ntoken, ninp, nhead, nhid, nlayers, dropout=0.5):\n","        super(TransformerModel, self).__init__(d_model=ninp,\n","                                               nhead=nhead,\n","                                               dim_feedforward=nhid,\n","                                               num_encoder_layers=nlayers)\n","        self.input_emb = nn.Embedding(ntoken, ninp)\n","        self.pos_encoder = PositionalEncoding(ninp, dropout)\n","        self.decoder = nn.Linear(ninp, ntoken)\n","\n","        self.ninp = ninp\n","        self.init_weights()\n","\n","    def init_weights(self):\n","        initrange = 0.1\n","        nn.init.uniform_(self.input_emb.weight, -initrange, initrange)\n","        nn.init.zeros_(self.decoder.bias)\n","        nn.init.uniform_(self.decoder.weight, -initrange, initrange)\n","\n","    def _generate_square_subsequent_mask(self, sz):\n","        return torch.log(torch.tril(torch.ones(sz,sz)))\n","\n","    def forward(self, src):\n","        mask = self._generate_square_subsequent_mask(len(src)).to(device)\n","        self.src_mask = mask\n","\n","        src = self.input_emb(src) * math.sqrt(self.ninp)\n","        src = self.pos_encoder(src)\n","        output_enc = self.encoder(src, mask=self.src_mask)\n","        output_dec = self.decoder(output_enc)\n","        return F.log_softmax(output_dec, dim=-1), output_enc"]},{"cell_type":"code","execution_count":21,"id":"1d568cc4","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":35,"status":"ok","timestamp":1738666481268,"user":{"displayName":"Nathanaël Fijalkow","userId":"05325553244112431603"},"user_tz":-60},"id":"1d568cc4","outputId":"80a9583f-ce2c-47f7-e972-af30867aef18"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["cuda\n"]},{"data":{"text/plain":["TransformerModel(\n","  (encoder): TransformerEncoder(\n","    (layers): ModuleList(\n","      (0-7): 8 x TransformerEncoderLayer(\n","        (self_attn): MultiheadAttention(\n","          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n","        )\n","        (linear1): Linear(in_features=128, out_features=64, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","        (linear2): Linear(in_features=64, out_features=128, bias=True)\n","        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","        (dropout1): Dropout(p=0.1, inplace=False)\n","        (dropout2): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","  )\n","  (decoder): Linear(in_features=128, out_features=16, bias=True)\n","  (input_emb): Embedding(16, 128)\n","  (pos_encoder): PositionalEncoding(\n","    (dropout): Dropout(p=0.5, inplace=False)\n","  )\n",")"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["model = TransformerModel(ntoken = ntokens,\n","                         ninp = 128,\n","                         nhead = 16,\n","                         nhid = 64,\n","                         nlayers = 8)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(device)\n","model.to(device)"]},{"cell_type":"code","execution_count":22,"id":"8f2f06e0","metadata":{"colab":{"background_save":true},"executionInfo":{"elapsed":31,"status":"ok","timestamp":1738666481268,"user":{"displayName":"Nathanaël Fijalkow","userId":"05325553244112431603"},"user_tz":-60},"id":"8f2f06e0"},"outputs":[],"source":["def generate(model, prompts, new_tokens = 5):\n","    input_tensor = prompts # (length_prompts, batch_size)\n","    input_tensor = input_tensor.to(device)\n","    for _ in range(new_tokens):\n","        output, _ = model(input_tensor) # (length_prompts, batch_size, ntokens)\n","        last_output = output[-1,:,:] # (batch_size, ntokens)\n","        token = torch.argmax(last_output, -1).view((1,-1)) # (1, batch_size)\n","        input_tensor = torch.cat((input_tensor, token), 0)\n","    return input_tensor"]},{"cell_type":"code","execution_count":35,"id":"d76d1b19","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1902,"status":"ok","timestamp":1738666655088,"user":{"displayName":"Nathanaël Fijalkow","userId":"05325553244112431603"},"user_tz":-60},"id":"d76d1b19"},"outputs":[{"data":{"text/plain":["(tensor([[12,  2, 13,  3, 11, 13, 13, 13, 13, 13]], device='cuda:0'),\n"," '2 + 3 = ')"]},"execution_count":58,"metadata":{},"output_type":"execute_result"}],"source":["model.eval()\n","\n","prompt = \"2+3=\"\n","prompt_tensor = torch.tensor(tokenizer.encode(prompt)).view((-1,1))\n","output = generate(model, prompt_tensor).view((1,-1))\n","output, tokenizer.decode(output.tolist()[0])"]},{"cell_type":"code","execution_count":24,"id":"00954ddc","metadata":{"colab":{"background_save":true},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1738666481269,"user":{"displayName":"Nathanaël Fijalkow","userId":"05325553244112431603"},"user_tz":-60},"id":"00954ddc"},"outputs":[],"source":["def pad(token_list, type_list = \"prompts\"):\n","    max_length = max([len(x) for x in token_list])\n","    out = []\n","    for x in token_list:\n","        if type_list == \"prompts\":\n","            out.append([tokenizer.token_to_id[pad_token]] * (max_length - len(x)) + x)\n","        if type_list == \"answers\":\n","            out.append(x + [tokenizer.token_to_id[eos_token]] + [tokenizer.token_to_id[pad_token]] * (max_length - len(x)))\n","    return out, max_length"]},{"cell_type":"code","execution_count":25,"id":"2c84beab","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1738666481269,"user":{"displayName":"Nathanaël Fijalkow","userId":"05325553244112431603"},"user_tz":-60},"id":"2c84beab"},"outputs":[{"data":{"text/plain":["(['1 + 1 = ', '21 + 35 = '], ['2', '56'])"]},"execution_count":60,"metadata":{},"output_type":"execute_result"}],"source":["prompts = [tokenizer.encode(\"1+1=\"), tokenizer.encode(\"21+35=\")]\n","answers = [tokenizer.encode(\"2\"), tokenizer.encode(\"56\")]\n","padded_prompts, _ = pad(prompts, \"prompts\")\n","padded_answers, _ = pad(answers, \"answers\")\n","padded_prompts, padded_answers\n","[tokenizer.decode(p) for p in padded_prompts], [tokenizer.decode(p) for p in padded_answers]"]},{"cell_type":"code","execution_count":26,"id":"264f9227","metadata":{"colab":{"background_save":true},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1738666481269,"user":{"displayName":"Nathanaël Fijalkow","userId":"05325553244112431603"},"user_tz":-60},"id":"264f9227"},"outputs":[],"source":["def get_batch(split, i):\n","    data = data_train if split == 'train' else data_test\n","    prompts = [tokenizer.encode(data[i][0]) for i in range(i, i + batch_size)]\n","    padded_prompts, length_prompts = pad(prompts, \"prompts\")\n","    answers = [tokenizer.encode(data[i][1]) for i in range(i, i + batch_size)]\n","    padded_answers, length_answers = pad(answers, \"answers\")\n","    X = torch.stack([torch.tensor(x) for x in padded_prompts], 1)\n","    Y = torch.stack([torch.tensor(x) for x in padded_answers], 1)\n","    return X, Y, length_prompts, length_answers"]},{"cell_type":"code","execution_count":27,"id":"91e281ad","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1738666481270,"user":{"displayName":"Nathanaël Fijalkow","userId":"05325553244112431603"},"user_tz":-60},"id":"91e281ad"},"outputs":[{"data":{"text/plain":["(torch.Size([13, 64]), torch.Size([5, 64]), 13, 4)"]},"execution_count":62,"metadata":{},"output_type":"execute_result"}],"source":["X, Y, length_prompts, length_answers = get_batch(\"train\", 243)\n","X.shape, Y.shape, length_prompts, length_answers"]},{"cell_type":"markdown","id":"113e1fd1","metadata":{"id":"113e1fd1"},"source":["## Step 4: Evaluate"]},{"cell_type":"code","execution_count":28,"id":"1cfcd10a","metadata":{"colab":{"background_save":true},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1738666481270,"user":{"displayName":"Nathanaël Fijalkow","userId":"05325553244112431603"},"user_tz":-60},"id":"1cfcd10a"},"outputs":[],"source":["def evaluate():\n","    # Turn on evaluation mode disables dropout.\n","    model.eval()\n","    correct = 0.\n","    with torch.no_grad():\n","        for batch, i in enumerate(range(0, len(data_test) - 1, batch_size)):\n","            prompts, target_answers, length_prompts, length_answers = get_batch(\"test\", i)\n","            prompts = prompts.to(device) # (length_prompts, batch_size)\n","            target_answers = target_answers.to(device) # (length_answers + 1, batch_size)\n","            output = generate(model, prompts, length_answers + 1) # (length_prompts + length_answers + 1, batch_size)\n","            answers_tokens = output[length_prompts:, :] # (length_answers + 1, batch_size), contains tokens\n","            equality_test = answers_tokens == target_answers # (length_answers + 1, batch_size), contains boolean values\n","            correct += torch.all(equality_test, axis=0).float().sum()\n","        accuracy = correct / len(data_test)\n","    return accuracy.item()"]},{"cell_type":"code","execution_count":29,"id":"ac335b05","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5604,"status":"ok","timestamp":1738666486865,"user":{"displayName":"Nathanaël Fijalkow","userId":"05325553244112431603"},"user_tz":-60},"id":"ac335b05","outputId":"8e9817bc-6382-4663-d71d-6b4690bf9513"},"outputs":[{"data":{"text/plain":["0.0"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["evaluate()"]},{"cell_type":"markdown","id":"4c54061a","metadata":{"id":"4c54061a"},"source":["## Step 4: Train the model"]},{"cell_type":"code","execution_count":30,"id":"3638a75d","metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1738666486865,"user":{"displayName":"Nathanaël Fijalkow","userId":"05325553244112431603"},"user_tz":-60},"id":"3638a75d"},"outputs":[],"source":["def train_epoch():\n","    model.train()\n","    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n","    total_loss = 0.\n","    start_time = time.time()\n","    for batch, i in enumerate(range(0, len(data_train) - 1, batch_size)):\n","        prompts, target_answers, length_prompts, length_answers = get_batch(\"train\", i)\n","        prompts = prompts.to(device) # (length_prompts, batch_size)\n","        target_answers = target_answers.to(device) # (length_answers, batch_size)\n","        input_tensor = torch.cat((prompts, target_answers), 0) # (length_prompts + length_answers, batch_size)\n","        model.zero_grad()\n","        output, _ = model(input_tensor) # (length_prompts + length_answers, batch_size, ntokens)\n","        output_answers = output[length_prompts-1:-1,:,:].reshape(-1, ntokens) # (length_answers * batch_size, ntokens)\n","        target_answers = target_answers.view(-1)\n","        loss = F.cross_entropy(output_answers, target_answers)\n","        loss.backward()\n","        optimizer.step()\n","\n","        total_loss += loss.item()\n","\n","        if batch % log_interval == 0 and batch \u003e 0:\n","            cur_loss = total_loss / log_interval\n","            elapsed = time.time() - start_time\n","            print('| {:5d}/{:5d} batches | ms/batch {:5.2f} | loss {:5.2f} | perplexity {:8.2f}'.format(batch, len(data_train) // batch_size,\n","                                                                                                        elapsed * 1000 / log_interval, cur_loss, math.exp(cur_loss)))\n","            total_loss = 0\n","            start_time = time.time()\n","\n","def train():\n","    best_test_accuracy = None\n","    test_accuracy = evaluate()\n","    print('-' * 89)\n","    print('| initialisation | test accuracy {:5.2f}'.format(test_accuracy))\n","    print('-' * 89)\n","    for epoch in range(1, epochs+1):\n","        epoch_start_time = time.time()\n","        train_epoch()\n","        test_accuracy = evaluate()\n","        print('-' * 89)\n","        print('| end of epoch {:3d} | time: {:5.2f}s | test accuracy {:5.2f}'.format(epoch, (time.time() - epoch_start_time), test_accuracy))\n","        print('-' * 89)\n","        # Save the model if the test accuracy is the best we've seen so far.\n","        if not best_test_accuracy or test_accuracy \u003c best_test_accuracy:\n","            with open(\"arithmetic.pt\", 'wb') as f:\n","                torch.save(model, f)\n","            best_test_accuracy = test_accuracy"]},{"cell_type":"code","execution_count":31,"id":"4e2a8490","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":101073,"status":"ok","timestamp":1738666587934,"user":{"displayName":"Nathanaël Fijalkow","userId":"05325553244112431603"},"user_tz":-60},"id":"4e2a8490"},"outputs":[{"name":"stdout","output_type":"stream","text":["-----------------------------------------------------------------------------------------\n","| initialisation | test accuracy  0.00\n","-----------------------------------------------------------------------------------------\n","|   200/  900 batches | ms/batch 21.59 | loss  2.17 | perplexity     8.78\n","|   400/  900 batches | ms/batch 25.82 | loss  1.74 | perplexity     5.71\n","|   600/  900 batches | ms/batch 21.20 | loss  1.62 | perplexity     5.07\n","|   800/  900 batches | ms/batch 21.80 | loss  1.55 | perplexity     4.69\n","-----------------------------------------------------------------------------------------\n","| end of epoch   1 | time: 23.68s | test accuracy  0.00\n","-----------------------------------------------------------------------------------------\n","|   200/  900 batches | ms/batch 21.30 | loss  1.48 | perplexity     4.40\n","|   400/  900 batches | ms/batch 24.46 | loss  1.44 | perplexity     4.21\n","|   600/  900 batches | ms/batch 22.57 | loss  1.41 | perplexity     4.08\n","|   800/  900 batches | ms/batch 21.29 | loss  1.36 | perplexity     3.90\n","-----------------------------------------------------------------------------------------\n","| end of epoch   2 | time: 23.83s | test accuracy  0.00\n","-----------------------------------------------------------------------------------------\n","|   200/  900 batches | ms/batch 21.58 | loss  1.31 | perplexity     3.72\n","|   400/  900 batches | ms/batch 21.40 | loss  1.28 | perplexity     3.59\n","|   600/  900 batches | ms/batch 25.94 | loss  1.25 | perplexity     3.49\n","|   800/  900 batches | ms/batch 21.67 | loss  1.23 | perplexity     3.42\n","-----------------------------------------------------------------------------------------\n","| end of epoch   3 | time: 23.18s | test accuracy  0.01\n","-----------------------------------------------------------------------------------------\n","|   200/  900 batches | ms/batch 32.37 | loss  1.21 | perplexity     3.37\n","|   400/  900 batches | ms/batch 22.43 | loss  1.19 | perplexity     3.29\n","|   600/  900 batches | ms/batch 25.90 | loss  1.18 | perplexity     3.25\n","|   800/  900 batches | ms/batch 21.61 | loss  1.17 | perplexity     3.21\n","-----------------------------------------------------------------------------------------\n","| end of epoch   4 | time: 25.62s | test accuracy  0.01\n","-----------------------------------------------------------------------------------------\n"]}],"source":["train()"]},{"cell_type":"code","execution_count":32,"id":"56d9d440","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1738666587934,"user":{"displayName":"Nathanaël Fijalkow","userId":"05325553244112431603"},"user_tz":-60},"id":"56d9d440"},"outputs":[{"name":"stdout","output_type":"stream","text":["724 + 472 = 1111\t actual result: 1196\n","404 + 604 = 1000\t actual result: 1008\n","378 + 910 = 1218\t actual result: 1288\n","232 + 271 = 411\t actual result: 503\n","160 + 275 = 311\t actual result: 435\n","110 + 496 = 591\t actual result: 606\n","121 + 976 = 1011\t actual result: 1097\n","419 + 617 = 1000\t actual result: 1036\n","257 + 106 = 211\t actual result: 363\n","866 + 194 = 1000\t actual result: 1060\n","414 + 005 = 410\t actual result: 419\n","343 + 459 = 799\t actual result: 802\n","105 + 035 = 101\t actual result: 140\n","598 + 565 = 1110\t actual result: 1163\n","817 + 068 = 901\t actual result: 885\n","376 + 794 = 1100\t actual result: 1170\n","331 + 074 = 310\t actual result: 405\n","172 + 646 = 801\t actual result: 818\n","627 + 115 = 711\t actual result: 742\n","742 + 806 = 1611\t actual result: 1548\n"]}],"source":["model.eval()\n","\n","for i in range(20):\n","    prompt, answers = data_test[i]\n","    prompt_tensor = torch.tensor(tokenizer.encode(prompt)).view((-1,1))\n","    output = generate(model, prompt_tensor, len(answers)).view((1,-1))\n","    print(tokenizer.decode(output.tolist()[0]) + \"\\t actual result: \" + answers)"]},{"cell_type":"markdown","id":"qJ9IOZu8Xo4Y","metadata":{"id":"qJ9IOZu8Xo4Y"},"source":["## Probing"]},{"cell_type":"code","execution_count":33,"id":"yomPfirhXkLb","metadata":{"colab":{"background_save":true},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1738666587934,"user":{"displayName":"Nathanaël Fijalkow","userId":"05325553244112431603"},"user_tz":-60},"id":"yomPfirhXkLb"},"outputs":[],"source":["import numpy as np\n","\n","train_size = 1000\n","test_size = 100\n","\n","model.eval()\n","\n","def data_probing(size):\n","    X = []\n","    y = np.zeros(size)\n","    for i in range(size):\n","        input = torch.tensor(tokenizer.encode(data[i][0])).view((-1, 1)).to(device)\n","        _, output = model(input)\n","        output = output[-1,:,:].flatten()\n","        # determine whether there was a carry in the result:\n","        carry = len(data[i][1]) \u003e len(data[i][0]) / 2\n","        X.append(output.cpu().detach().numpy())\n","        y[i] = carry\n","    return np.array(X), y"]},{"cell_type":"code","execution_count":34,"id":"QGmfXVxkppfP","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8217,"status":"ok","timestamp":1738666596145,"user":{"displayName":"Nathanaël Fijalkow","userId":"05325553244112431603"},"user_tz":-60},"id":"QGmfXVxkppfP"},"outputs":[{"data":{"text/plain":["0.99"]},"execution_count":69,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.linear_model import LogisticRegression\n","from sklearn.preprocessing import StandardScaler\n","\n","X_train, y_train = data_probing(train_size)\n","X_test, y_test = data_probing(test_size)\n","\n","scaler = StandardScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_test = scaler.fit_transform(X_test)\n","\n","reg = LogisticRegression()\n","reg.fit(X_train,y_train)\n","reg.score(X_test, y_test)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","name":"","version":""},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":5}